{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* This line imports the necessary classes from the PySpark library. `SparkConf` is used to configure the Spark application, and `SparkContext` is the entry point to Spark functionality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf, SparkContext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This line set up the Spark configuration and initialize the Spark context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = SparkConf().setMaster(\"local\").setAppName(\"NumberFriendsByAge\")\n",
    "sc = SparkContext(conf = conf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `setMaster(\"local\")` tells Spark to run locally with one thread (no distributed computing).\n",
    "* `setAppName(\"FriendsByAge\")` names the Spark application \"FriendsByAge\". This name will be invisible in the Spark web UI and logs. By setting an appropiate and meaningful application name, you can make it easier for yourself and others to manage and debug the Spark application effectively.\n",
    "* `SparkContext(conf = conf)` initializes the Spark context with the given configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PareLine(line):\n",
    "    fields = line.split(',')\n",
    "    age = int(fields[2])\n",
    "    numFriends = int(fields[3])\n",
    "    return (age, numFriends)\n",
    "\n",
    "# This function `PareLine` takes a line of text from the input data (Which is expected to be a CSV), splits it by comma, and extracts the `age` and `numFriends` fields.\n",
    "# It returns a tuple `(age, numFriends)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = sc.textFile(\"./fakefriends.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = lines.map(PareLine)\n",
    "# THis applies the `PareLine` function to each element of the `lines` RDD, transforming it into a new RDD where each element is a tuple `(age, numFriends)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of `map` Transformation\n",
    "The `map` transformation is one of the most commonly used operations in Apache Spark. It applies a given function to each element of an RDD, resulting in a new RDD containing the transformed elements.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalsByAge = rdd.mapValues(lambda x: (x, 1)).reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detailed Explanation\n",
    "**1. Input RDD: `lines`**\n",
    "* Type: `RDD[String]`\n",
    "* Content: Each element is a line of text from the `fakefriends.csv` file. for example it will contain the following lines:\n",
    "```bash\n",
    "0,Will,33,385\n",
    "1,Jean,26,2\n",
    "2,Jane,45,2\n",
    "```\n",
    "then the `lines` RDD will have\n",
    "```css\n",
    "[\"0,Will,33,385\", \"1,Jean,26,2\", \"2,Jane,45,2\"]\n",
    "```\n",
    "\n",
    "**2. Applying `map(PareLine)`**\n",
    "The `map` transformation applies the `PareLine` function to each element of the `lines RDD. This results in a new RDD where each line has been transformed from a string to a tuple containing the age and the number of friends.\n",
    "\n",
    "### Visual Representation\n",
    "Here is a visual representation of how `map(PareLine)` transforms the data:\n",
    "```less\n",
    "Input RDD (lines):\n",
    "[\"0,Will,33,385\", \"1,Jean,26,2\", \"2,Jane,45,2\"]\n",
    "\n",
    "After map(PareLine):\n",
    "[(33, 385), (26, 2), (45, 2)]\n",
    "```\n",
    "\n",
    "### Why use `map`?\n",
    "The `map` transformation is useful for:\n",
    "* **Data Cleaning**: Converting raw data into a more useful format.\n",
    "* **Feature Extraction**: Extracting relevant fields from input data.\n",
    "* **Transformation**: Applying any kind of transformation or computation to each element."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step-by-step Explanation\n",
    "#### 1. Input RDD: `rdd`\n",
    "* Type: `RDD[(int, int)]`\n",
    "* Content: Each element is a tuple `(age, numFriends)`\n",
    "* Example: `[(33, 385), (26, 2), (45, 2)]`\n",
    "\n",
    "#### 2. Transformation: `mapValues(lambda x: (x,1))`\n",
    "* Purpose: To transform each value in the RDD while keeping the key unchanged.\n",
    "  * Input: `x` is the number of friends.\n",
    "  * Output: A tuple `(x, 1)` where `x` is the number of friends and 1 is the count.\n",
    "\n",
    "**Results**: The resulting RDD will have the same keys (age) but the values will be transformed into tuples `(numFriends, 1)`.\n",
    "\n",
    "**Example**:\n",
    "* Before `mapValues`: `[(33, 385), (26, 2), (45, 2)]`\n",
    "* After `mapValues`: `[(33, (385, 1)), (26, (2, 1)), (45, (2, 1))]`\n",
    "\n",
    "#### 3. Transformation: `reduceByKey(lambda x, y: (x[0] + y[0], x[1] + y[1]))`\n",
    "* Purpose: To aggregate the values for each key (age) by summing up the number of friends and the count.\n",
    "* Function: lambda x, y: (x[0] + y[0], x[1] + y[1])\n",
    "  * Input: x and y are tuples of the form `(numFriends, count)`.\n",
    "  * Output: A new tuple where:\n",
    "    * The first element is the sum of the number of friends.\n",
    "    * The second element is the sum of the counts.\n",
    "\n",
    "**Explanation**: `reduceByKey` groups the values by key (age) and applies the given function to combine the values\n",
    "\n",
    "**Resulting RDD**: \n",
    "* After `reduceByKey`, the RDD will contain tuples where the first element is the age and the second element is a tuple with the total number of friends and the count of entries for that age.\n",
    "**Example**: Result: `[(33, (395, 2)), (26, (10, 2)), (45, (2, 1))]`\n",
    "\n",
    "#### Result\n",
    "The resulting `totalsByAge` RDD contains the total number of friends and the total count of entries for each age. This prepares the data for calculating the average number of friends per age in the next step of the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = averagesByAge.collect()\n",
    "# This collect the results from the \"averagesByAge` RDD into a list on the driver node. this is an action that triggers the excution of the RDD transformations and brings the results to the driver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for No in final_results:\n",
    "    print(f\"Age: {No[0]}, Average Number of Friends: {No[1]:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
